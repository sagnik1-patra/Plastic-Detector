{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "422a59a7-cf9a-4f28-a2e7-416f2ddd607a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Data root: C:\\Users\\sagni\\Downloads\\Plastic Detector\\archive\\dataset-resized\n",
      "[INFO] Classes: ['cardboard', 'glass', 'metal', 'paper', 'plastic', 'trash']\n",
      "Found 2024 images belonging to 6 classes.\n",
      "Found 503 images belonging to 6 classes.\n",
      "[INFO] Class indices: {'cardboard': 0, 'glass': 1, 'metal': 2, 'paper': 3, 'plastic': 4, 'trash': 5}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ efficientnetb0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)          │       <span style=\"color: #00af00; text-decoration-color: #00af00\">4,049,571</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling2d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)                   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">7,686</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ efficientnetb0 (\u001b[38;5;33mFunctional\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1280\u001b[0m)          │       \u001b[38;5;34m4,049,571\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling2d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)                   │           \u001b[38;5;34m7,686\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,057,257</span> (15.48 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,057,257\u001b[0m (15.48 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,686</span> (30.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,686\u001b[0m (30.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,049,571</span> (15.45 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m4,049,571\u001b[0m (15.45 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sagni\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 593ms/step - accuracy: 0.5149 - loss: 1.3329\n",
      "Epoch 1: val_accuracy improved from -inf to 0.75149, saving model to C:\\Users\\sagni\\Downloads\\Plastic Detector\\model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 767ms/step - accuracy: 0.5171 - loss: 1.3281 - val_accuracy: 0.7515 - val_loss: 0.7417 - learning_rate: 0.0010\n",
      "Epoch 2/12\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 578ms/step - accuracy: 0.8090 - loss: 0.5856\n",
      "Epoch 2: val_accuracy improved from 0.75149 to 0.79523, saving model to C:\\Users\\sagni\\Downloads\\Plastic Detector\\model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 668ms/step - accuracy: 0.8091 - loss: 0.5853 - val_accuracy: 0.7952 - val_loss: 0.5951 - learning_rate: 0.0010\n",
      "Epoch 3/12\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 593ms/step - accuracy: 0.8416 - loss: 0.4920\n",
      "Epoch 3: val_accuracy improved from 0.79523 to 0.80318, saving model to C:\\Users\\sagni\\Downloads\\Plastic Detector\\model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 680ms/step - accuracy: 0.8417 - loss: 0.4915 - val_accuracy: 0.8032 - val_loss: 0.5392 - learning_rate: 0.0010\n",
      "Epoch 4/12\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580ms/step - accuracy: 0.8663 - loss: 0.3918\n",
      "Epoch 4: val_accuracy improved from 0.80318 to 0.81909, saving model to C:\\Users\\sagni\\Downloads\\Plastic Detector\\model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 676ms/step - accuracy: 0.8663 - loss: 0.3918 - val_accuracy: 0.8191 - val_loss: 0.5196 - learning_rate: 0.0010\n",
      "Epoch 5/12\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8781 - loss: 0.3590\n",
      "Epoch 5: val_accuracy improved from 0.81909 to 0.82306, saving model to C:\\Users\\sagni\\Downloads\\Plastic Detector\\model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 2s/step - accuracy: 0.8781 - loss: 0.3590 - val_accuracy: 0.8231 - val_loss: 0.4912 - learning_rate: 0.0010\n",
      "Epoch 6/12\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 584ms/step - accuracy: 0.8807 - loss: 0.3371\n",
      "Epoch 6: val_accuracy improved from 0.82306 to 0.83499, saving model to C:\\Users\\sagni\\Downloads\\Plastic Detector\\model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 673ms/step - accuracy: 0.8807 - loss: 0.3372 - val_accuracy: 0.8350 - val_loss: 0.4766 - learning_rate: 0.0010\n",
      "Epoch 7/12\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 606ms/step - accuracy: 0.9061 - loss: 0.2780\n",
      "Epoch 7: val_accuracy did not improve from 0.83499\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 688ms/step - accuracy: 0.9059 - loss: 0.2785 - val_accuracy: 0.8330 - val_loss: 0.4677 - learning_rate: 0.0010\n",
      "Epoch 8/12\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 619ms/step - accuracy: 0.9108 - loss: 0.2917\n",
      "Epoch 8: val_accuracy did not improve from 0.83499\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 707ms/step - accuracy: 0.9108 - loss: 0.2917 - val_accuracy: 0.8270 - val_loss: 0.4720 - learning_rate: 0.0010\n",
      "Epoch 9/12\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 577ms/step - accuracy: 0.9094 - loss: 0.2835\n",
      "Epoch 9: val_accuracy improved from 0.83499 to 0.84095, saving model to C:\\Users\\sagni\\Downloads\\Plastic Detector\\model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 666ms/step - accuracy: 0.9094 - loss: 0.2834 - val_accuracy: 0.8410 - val_loss: 0.4447 - learning_rate: 0.0010\n",
      "Epoch 10/12\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 763ms/step - accuracy: 0.9117 - loss: 0.2687\n",
      "Epoch 10: val_accuracy improved from 0.84095 to 0.86084, saving model to C:\\Users\\sagni\\Downloads\\Plastic Detector\\model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 852ms/step - accuracy: 0.9118 - loss: 0.2684 - val_accuracy: 0.8608 - val_loss: 0.4439 - learning_rate: 0.0010\n",
      "Epoch 11/12\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590ms/step - accuracy: 0.9145 - loss: 0.2503\n",
      "Epoch 11: val_accuracy did not improve from 0.86084\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 673ms/step - accuracy: 0.9146 - loss: 0.2503 - val_accuracy: 0.8569 - val_loss: 0.4304 - learning_rate: 0.0010\n",
      "Epoch 12/12\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 620ms/step - accuracy: 0.9209 - loss: 0.2471\n",
      "Epoch 12: val_accuracy did not improve from 0.86084\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 703ms/step - accuracy: 0.9210 - loss: 0.2469 - val_accuracy: 0.8509 - val_loss: 0.4264 - learning_rate: 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Saved model: C:\\Users\\sagni\\Downloads\\Plastic Detector\\model.h5\n",
      "[INFO] Saved class indices: C:\\Users\\sagni\\Downloads\\Plastic Detector\\class_indices.pkl\n",
      "[INFO] Saved metrics: C:\\Users\\sagni\\Downloads\\Plastic Detector\\metrics.json\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 633ms/step\n",
      "[INFO] Saved validation predictions: C:\\Users\\sagni\\Downloads\\Plastic Detector\\val_predictions.json\n",
      "[INFO] Saved accuracy/loss plots: C:\\Users\\sagni\\Downloads\\Plastic Detector\\accuracy_loss.png (+ separate _acc/_loss PNGs)\n",
      "[INFO] Saved classification report CSV: C:\\Users\\sagni\\Downloads\\Plastic Detector\\classification_report.csv\n",
      "[INFO] Saved confusion matrix CSV: C:\\Users\\sagni\\Downloads\\Plastic Detector\\confusion_matrix.csv\n",
      "[INFO] Saved confusion matrix heatmap: C:\\Users\\sagni\\Downloads\\Plastic Detector\\confusion_matrix.png\n",
      "[INFO] Saved run config: C:\\Users\\sagni\\Downloads\\Plastic Detector\\run_config.yaml\n",
      "\n",
      "[DONE] All artifacts saved to: C:\\Users\\sagni\\Downloads\\Plastic Detector\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import yaml\n",
    "import pickle\n",
    "import random\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "from typing import Dict, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ML / DL\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "# Metrics / Plots\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import itertools\n",
    "\n",
    "# ----------------------------\n",
    "# CONFIG (Windows raw strings)\n",
    "# ----------------------------\n",
    "DATA_DIRS = [\n",
    "    r\"C:\\Users\\sagni\\Downloads\\Plastic Detector\\archive\\dataset-resized\\plastic\",\n",
    "    r\"C:\\Users\\sagni\\Downloads\\Plastic Detector\\archive\\dataset-resized\\trash\",\n",
    "    r\"C:\\Users\\sagni\\Downloads\\Plastic Detector\\archive\\dataset-resized\\paper\",\n",
    "    r\"C:\\Users\\sagni\\Downloads\\Plastic Detector\\archive\\dataset-resized\\metal\",\n",
    "    r\"C:\\Users\\sagni\\Downloads\\Plastic Detector\\archive\\dataset-resized\\glass\",\n",
    "    r\"C:\\Users\\sagni\\Downloads\\Plastic Detector\\archive\\dataset-resized\\cardboard\",\n",
    "]\n",
    "# Parent directory containing all class folders (…\\dataset-resized)\n",
    "DATA_ROOT = str(Path(DATA_DIRS[0]).parent)\n",
    "\n",
    "OUTPUT_DIR = r\"C:\\Users\\sagni\\Downloads\\Plastic Detector\"\n",
    "MODEL_H5 = str(Path(OUTPUT_DIR) / \"model.h5\")\n",
    "CLASS_PKL = str(Path(OUTPUT_DIR) / \"class_indices.pkl\")\n",
    "RUN_YAML  = str(Path(OUTPUT_DIR) / \"run_config.yaml\")\n",
    "METRICS_JSON = str(Path(OUTPUT_DIR) / \"metrics.json\")\n",
    "VAL_PRED_JSON = str(Path(OUTPUT_DIR) / \"val_predictions.json\")\n",
    "\n",
    "# Plot / report artifacts\n",
    "ACC_PNG = str(Path(OUTPUT_DIR) / \"accuracy_loss.png\")\n",
    "CM_PNG  = str(Path(OUTPUT_DIR) / \"confusion_matrix.png\")\n",
    "CR_CSV  = str(Path(OUTPUT_DIR) / \"classification_report.csv\")\n",
    "CM_CSV  = str(Path(OUTPUT_DIR) / \"confusion_matrix.csv\")\n",
    "\n",
    "# Training hyperparams\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 12\n",
    "VAL_SPLIT = 0.2\n",
    "SEED = 42\n",
    "LEARNING_RATE = 1e-3\n",
    "AUGMENT = True  # set False for baseline\n",
    "\n",
    "# ----------------------------\n",
    "# Reproducibility\n",
    "# ----------------------------\n",
    "def set_seed(seed=SEED):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "set_seed(SEED)\n",
    "\n",
    "# ----------------------------\n",
    "# Prepare output directory\n",
    "# ----------------------------\n",
    "Path(OUTPUT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ----------------------------\n",
    "# Verify folders exist\n",
    "# ----------------------------\n",
    "expected_classes = sorted([Path(p).name for p in DATA_DIRS])\n",
    "if not Path(DATA_ROOT).exists():\n",
    "    raise FileNotFoundError(f\"DATA_ROOT not found: {DATA_ROOT}\")\n",
    "for p in DATA_DIRS:\n",
    "    if not Path(p).exists():\n",
    "        raise FileNotFoundError(f\"Class folder missing: {p}\")\n",
    "\n",
    "print(\"[INFO] Data root:\", DATA_ROOT)\n",
    "print(\"[INFO] Classes:\", expected_classes)\n",
    "\n",
    "# ----------------------------\n",
    "# Data generators (Keras)\n",
    "# ----------------------------\n",
    "if AUGMENT:\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        preprocessing_function=preprocess_input,\n",
    "        validation_split=VAL_SPLIT,\n",
    "        rotation_range=15,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        zoom_range=0.1,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode=\"nearest\",\n",
    "    )\n",
    "else:\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        preprocessing_function=preprocess_input,\n",
    "        validation_split=VAL_SPLIT,\n",
    "    )\n",
    "\n",
    "val_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    validation_split=VAL_SPLIT\n",
    ")\n",
    "\n",
    "# Directory structure must be:\n",
    "# DATA_ROOT/cardboard, glass, metal, paper, plastic, trash\n",
    "train_gen = train_datagen.flow_from_directory(\n",
    "    DATA_ROOT,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    classes=expected_classes,     # lock class order to your folders\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    subset=\"training\",\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "val_gen = val_datagen.flow_from_directory(\n",
    "    DATA_ROOT,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    classes=expected_classes,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=False,\n",
    "    subset=\"validation\",\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "num_classes = len(train_gen.class_indices)\n",
    "print(\"[INFO] Class indices:\", train_gen.class_indices)\n",
    "\n",
    "# ----------------------------\n",
    "# Build model (EfficientNetB0 TL)\n",
    "# ----------------------------\n",
    "device_name = \"/GPU:0\" if tf.config.list_physical_devices(\"GPU\") else \"/CPU:0\"\n",
    "with tf.device(device_name):\n",
    "    base = EfficientNetB0(include_top=False, input_shape=(*IMG_SIZE, 3), weights=\"imagenet\")\n",
    "    base.trainable = False  # freeze backbone first\n",
    "\n",
    "    inputs = layers.Input(shape=(*IMG_SIZE, 3))\n",
    "    x = base(inputs, training=False)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "    model = models.Model(inputs, outputs)\n",
    "\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "    model.compile(optimizer=opt, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    model.summary()\n",
    "\n",
    "# ----------------------------\n",
    "# Callbacks\n",
    "# ----------------------------\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor=\"val_accuracy\", patience=3, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=2, min_lr=1e-6, verbose=1),\n",
    "    ModelCheckpoint(MODEL_H5, monitor=\"val_accuracy\", save_best_only=True, verbose=1)\n",
    "]\n",
    "\n",
    "# ----------------------------\n",
    "# Train\n",
    "# ----------------------------\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Optional quick fine-tune (uncomment to enable):\n",
    "# base.trainable = True\n",
    "# for layer in base.layers[:-40]:\n",
    "#     layer.trainable = False\n",
    "# model.compile(optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "#               loss=\"categorical_crossentropy\",\n",
    "#               metrics=[\"accuracy\"])\n",
    "# history_ft = model.fit(train_gen, validation_data=val_gen, epochs=4, callbacks=callbacks, verbose=1)\n",
    "\n",
    "# Ensure best model saved; also save current model graph\n",
    "model.save(MODEL_H5)\n",
    "print(f\"[INFO] Saved model: {MODEL_H5}\")\n",
    "\n",
    "# ----------------------------\n",
    "# Save class indices (PKL)\n",
    "# ----------------------------\n",
    "with open(CLASS_PKL, \"wb\") as f:\n",
    "    pickle.dump(train_gen.class_indices, f)\n",
    "print(f\"[INFO] Saved class indices: {CLASS_PKL}\")\n",
    "\n",
    "# ----------------------------\n",
    "# Compute and save metrics JSON\n",
    "# ----------------------------\n",
    "final_train_acc = float(history.history[\"accuracy\"][-1])\n",
    "final_train_loss = float(history.history[\"loss\"][-1])\n",
    "final_val_acc = float(history.history[\"val_accuracy\"][-1])\n",
    "final_val_loss = float(history.history[\"val_loss\"][-1])\n",
    "\n",
    "metrics_payload = {\n",
    "    \"timestamp\": datetime.datetime.now().isoformat(),\n",
    "    \"device\": device_name,\n",
    "    \"epochs_run\": len(history.history[\"loss\"]),\n",
    "    \"final\": {\n",
    "        \"train_accuracy\": final_train_acc,\n",
    "        \"train_loss\": final_train_loss,\n",
    "        \"val_accuracy\": final_val_acc,\n",
    "        \"val_loss\": final_val_loss\n",
    "    },\n",
    "    \"history\": {k: [float(x) for x in v] for k, v in history.history.items()}\n",
    "}\n",
    "\n",
    "with open(METRICS_JSON, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(metrics_payload, f, indent=2)\n",
    "print(f\"[INFO] Saved metrics: {METRICS_JSON}\")\n",
    "\n",
    "# ----------------------------\n",
    "# Validation predictions JSON\n",
    "# ----------------------------\n",
    "idx_to_class = {v: k for k, v in train_gen.class_indices.items()}\n",
    "\n",
    "val_gen.reset()\n",
    "all_probs = model.predict(val_gen, verbose=1)\n",
    "top1_idx = np.argmax(all_probs, axis=1)\n",
    "top1_conf = np.max(all_probs, axis=1)\n",
    "\n",
    "val_records = []\n",
    "for rel_path, pred_i, conf in zip(val_gen.filenames, top1_idx, top1_conf):\n",
    "    val_records.append({\n",
    "        \"file\": rel_path.replace(\"\\\\\", \"/\"),\n",
    "        \"pred_class\": idx_to_class[int(pred_i)],\n",
    "        \"confidence\": float(conf)\n",
    "    })\n",
    "\n",
    "with open(VAL_PRED_JSON, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(val_records, f, indent=2)\n",
    "print(f\"[INFO] Saved validation predictions: {VAL_PRED_JSON}\")\n",
    "\n",
    "# ----------------------------\n",
    "# PLOTS: Accuracy/Loss & Confusion Matrix\n",
    "# ----------------------------\n",
    "# 1) Accuracy & Loss curves (combined + separate)\n",
    "plt.figure(figsize=(9, 6))\n",
    "plt.plot(history.history[\"accuracy\"], label=\"Train Acc\")\n",
    "plt.plot(history.history[\"val_accuracy\"], label=\"Val Acc\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Training vs Validation Accuracy\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(alpha=0.25)\n",
    "plt.tight_layout()\n",
    "plt.savefig(ACC_PNG.replace(\".png\", \"_acc.png\"), dpi=200)\n",
    "plt.close()\n",
    "\n",
    "plt.figure(figsize=(9, 6))\n",
    "plt.plot(history.history[\"loss\"], label=\"Train Loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Val Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training vs Validation Loss\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.grid(alpha=0.25)\n",
    "plt.tight_layout()\n",
    "plt.savefig(ACC_PNG.replace(\".png\", \"_loss.png\"), dpi=200)\n",
    "plt.close()\n",
    "\n",
    "# Combined canvas\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax1 = fig.add_subplot(2, 1, 1)\n",
    "ax1.plot(history.history[\"accuracy\"], label=\"Train Acc\")\n",
    "ax1.plot(history.history[\"val_accuracy\"], label=\"Val Acc\")\n",
    "ax1.set_xlabel(\"Epoch\"); ax1.set_ylabel(\"Accuracy\"); ax1.set_title(\"Accuracy\")\n",
    "ax1.grid(alpha=0.25); ax1.legend(loc=\"lower right\")\n",
    "\n",
    "ax2 = fig.add_subplot(2, 1, 2)\n",
    "ax2.plot(history.history[\"loss\"], label=\"Train Loss\")\n",
    "ax2.plot(history.history[\"val_loss\"], label=\"Val Loss\")\n",
    "ax2.set_xlabel(\"Epoch\"); ax2.set_ylabel(\"Loss\"); ax2.set_title(\"Loss\")\n",
    "ax2.grid(alpha=0.25); ax2.legend(loc=\"upper right\")\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(ACC_PNG, dpi=200)\n",
    "plt.close(fig)\n",
    "\n",
    "print(f\"[INFO] Saved accuracy/loss plots: {ACC_PNG} (+ separate _acc/_loss PNGs)\")\n",
    "\n",
    "# 2) Confusion Matrix (counts + normalized heatmap) + reports\n",
    "y_true = val_gen.classes                            # true indices (order aligned to class_indices)\n",
    "labels_order = [idx_to_class[i] for i in range(num_classes)]\n",
    "cm = confusion_matrix(y_true, top1_idx, labels=list(range(num_classes)))\n",
    "cm_norm = cm.astype(\"float\") / cm.sum(axis=1, keepdims=True)\n",
    "cm_norm = np.nan_to_num(cm_norm)\n",
    "\n",
    "# Save raw counts and classification report\n",
    "pd.DataFrame(cm, index=labels_order, columns=labels_order).to_csv(CM_CSV, index=True)\n",
    "pd.DataFrame(\n",
    "    classification_report(y_true, top1_idx, target_names=labels_order, output_dict=True)\n",
    ").to_csv(CR_CSV)\n",
    "print(f\"[INFO] Saved classification report CSV: {CR_CSV}\")\n",
    "print(f\"[INFO] Saved confusion matrix CSV: {CM_CSV}\")\n",
    "\n",
    "# Plot normalized heatmap with annotations (counts + %)\n",
    "fig = plt.figure(figsize=(9, 7))\n",
    "ax = plt.gca()\n",
    "im = ax.imshow(cm_norm, interpolation=\"nearest\", cmap=\"viridis\")\n",
    "plt.title(\"Confusion Matrix (Normalized)\")\n",
    "cbar = plt.colorbar(im, fraction=0.046, pad=0.04)\n",
    "cbar.ax.set_ylabel(\"Proportion\", rotation=90)\n",
    "tick_marks = np.arange(len(labels_order))\n",
    "plt.xticks(tick_marks, labels_order, rotation=45, ha=\"right\")\n",
    "plt.yticks(tick_marks, labels_order)\n",
    "\n",
    "thresh = cm_norm.max() / 2.0\n",
    "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "    count = cm[i, j]\n",
    "    perc = cm_norm[i, j] * 100.0\n",
    "    txt = f\"{count}\\n{perc:.1f}%\"\n",
    "    ax.text(j, i, txt,\n",
    "            ha=\"center\", va=\"center\",\n",
    "            color=\"white\" if cm_norm[i, j] > thresh else \"black\",\n",
    "            fontsize=9)\n",
    "\n",
    "plt.ylabel(\"True label\")\n",
    "plt.xlabel(\"Predicted label\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(CM_PNG, dpi=220)\n",
    "plt.close(fig)\n",
    "\n",
    "print(f\"[INFO] Saved confusion matrix heatmap: {CM_PNG}\")\n",
    "\n",
    "# ----------------------------\n",
    "# Save YAML run config (last)\n",
    "# ----------------------------\n",
    "run_cfg = {\n",
    "    \"run\": {\n",
    "        \"timestamp\": datetime.datetime.now().isoformat(),\n",
    "        \"seed\": SEED,\n",
    "        \"device\": device_name\n",
    "    },\n",
    "    \"data\": {\n",
    "        \"data_root\": DATA_ROOT,\n",
    "        \"class_dirs\": DATA_DIRS,\n",
    "        \"classes\": expected_classes,\n",
    "        \"val_split\": VAL_SPLIT,\n",
    "        \"image_size\": list(IMG_SIZE),\n",
    "        \"batch_size\": BATCH_SIZE,\n",
    "        \"augment\": AUGMENT\n",
    "    },\n",
    "    \"model\": {\n",
    "        \"architecture\": \"EfficientNetB0\",\n",
    "        \"transfer_learning\": True,\n",
    "        \"frozen_base\": True,\n",
    "        \"optimizer\": \"Adam\",\n",
    "        \"learning_rate\": LEARNING_RATE,\n",
    "        \"epochs\": EPOCHS,\n",
    "        \"num_classes\": num_classes\n",
    "    },\n",
    "    \"artifacts\": {\n",
    "        \"model_h5\": MODEL_H5,\n",
    "        \"class_indices_pkl\": CLASS_PKL,\n",
    "        \"metrics_json\": METRICS_JSON,\n",
    "        \"val_predictions_json\": VAL_PRED_JSON,\n",
    "        \"accuracy_loss_png\": ACC_PNG,\n",
    "        \"confusion_matrix_png\": CM_PNG,\n",
    "        \"classification_report_csv\": CR_CSV,\n",
    "        \"confusion_matrix_csv\": CM_CSV\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(RUN_YAML, \"w\", encoding=\"utf-8\") as f:\n",
    "    yaml.safe_dump(run_cfg, f, sort_keys=False, allow_unicode=True)\n",
    "print(f\"[INFO] Saved run config: {RUN_YAML}\")\n",
    "\n",
    "print(\"\\n[DONE] All artifacts saved to:\", OUTPUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbb54ed-3d2e-4f3f-b07b-fefa42d1a856",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (moviepy)",
   "language": "python",
   "name": "py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
