{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aed26d7a-b493-4154-bc91-caeaae58a698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Data root: C:\\Users\\sagni\\Downloads\\Plastic Detector\\archive\\dataset-resized\n",
      "[INFO] Classes: ['cardboard', 'glass', 'metal', 'paper', 'plastic', 'trash']\n",
      "Found 2024 images belonging to 6 classes.\n",
      "Found 503 images belonging to 6 classes.\n",
      "[INFO] Class indices: {'cardboard': 0, 'glass': 1, 'metal': 2, 'paper': 3, 'plastic': 4, 'trash': 5}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ efficientnetb0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)          │       <span style=\"color: #00af00; text-decoration-color: #00af00\">4,049,571</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling2d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)                   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">7,686</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ efficientnetb0 (\u001b[38;5;33mFunctional\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1280\u001b[0m)          │       \u001b[38;5;34m4,049,571\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling2d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)                   │           \u001b[38;5;34m7,686\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,057,257</span> (15.48 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,057,257\u001b[0m (15.48 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,686</span> (30.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,686\u001b[0m (30.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,049,571</span> (15.45 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m4,049,571\u001b[0m (15.45 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sagni\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599ms/step - accuracy: 0.5149 - loss: 1.3329\n",
      "Epoch 1: val_accuracy improved from -inf to 0.75149, saving model to C:\\Users\\sagni\\Downloads\\Plastic Detector\\model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 772ms/step - accuracy: 0.5171 - loss: 1.3281 - val_accuracy: 0.7515 - val_loss: 0.7417 - learning_rate: 0.0010\n",
      "Epoch 2/12\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 574ms/step - accuracy: 0.8090 - loss: 0.5856\n",
      "Epoch 2: val_accuracy improved from 0.75149 to 0.79523, saving model to C:\\Users\\sagni\\Downloads\\Plastic Detector\\model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 665ms/step - accuracy: 0.8091 - loss: 0.5853 - val_accuracy: 0.7952 - val_loss: 0.5951 - learning_rate: 0.0010\n",
      "Epoch 3/12\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 566ms/step - accuracy: 0.8416 - loss: 0.4920\n",
      "Epoch 3: val_accuracy improved from 0.79523 to 0.80318, saving model to C:\\Users\\sagni\\Downloads\\Plastic Detector\\model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 659ms/step - accuracy: 0.8417 - loss: 0.4915 - val_accuracy: 0.8032 - val_loss: 0.5392 - learning_rate: 0.0010\n",
      "Epoch 4/12\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585ms/step - accuracy: 0.8663 - loss: 0.3918\n",
      "Epoch 4: val_accuracy improved from 0.80318 to 0.81909, saving model to C:\\Users\\sagni\\Downloads\\Plastic Detector\\model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 679ms/step - accuracy: 0.8663 - loss: 0.3918 - val_accuracy: 0.8191 - val_loss: 0.5196 - learning_rate: 0.0010\n",
      "Epoch 5/12\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562ms/step - accuracy: 0.8781 - loss: 0.3590\n",
      "Epoch 5: val_accuracy improved from 0.81909 to 0.82306, saving model to C:\\Users\\sagni\\Downloads\\Plastic Detector\\model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 651ms/step - accuracy: 0.8781 - loss: 0.3590 - val_accuracy: 0.8231 - val_loss: 0.4912 - learning_rate: 0.0010\n",
      "Epoch 6/12\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 569ms/step - accuracy: 0.8807 - loss: 0.3371\n",
      "Epoch 6: val_accuracy improved from 0.82306 to 0.83499, saving model to C:\\Users\\sagni\\Downloads\\Plastic Detector\\model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 663ms/step - accuracy: 0.8807 - loss: 0.3372 - val_accuracy: 0.8350 - val_loss: 0.4766 - learning_rate: 0.0010\n",
      "Epoch 7/12\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 571ms/step - accuracy: 0.9061 - loss: 0.2780\n",
      "Epoch 7: val_accuracy did not improve from 0.83499\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 655ms/step - accuracy: 0.9059 - loss: 0.2785 - val_accuracy: 0.8330 - val_loss: 0.4677 - learning_rate: 0.0010\n",
      "Epoch 8/12\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568ms/step - accuracy: 0.9108 - loss: 0.2917\n",
      "Epoch 8: val_accuracy did not improve from 0.83499\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 660ms/step - accuracy: 0.9108 - loss: 0.2917 - val_accuracy: 0.8270 - val_loss: 0.4720 - learning_rate: 0.0010\n",
      "Epoch 9/12\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568ms/step - accuracy: 0.9094 - loss: 0.2835\n",
      "Epoch 9: val_accuracy improved from 0.83499 to 0.84095, saving model to C:\\Users\\sagni\\Downloads\\Plastic Detector\\model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 663ms/step - accuracy: 0.9094 - loss: 0.2834 - val_accuracy: 0.8410 - val_loss: 0.4447 - learning_rate: 0.0010\n",
      "Epoch 10/12\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564ms/step - accuracy: 0.9117 - loss: 0.2687\n",
      "Epoch 10: val_accuracy improved from 0.84095 to 0.86084, saving model to C:\\Users\\sagni\\Downloads\\Plastic Detector\\model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 654ms/step - accuracy: 0.9118 - loss: 0.2684 - val_accuracy: 0.8608 - val_loss: 0.4439 - learning_rate: 0.0010\n",
      "Epoch 11/12\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9145 - loss: 0.2503\n",
      "Epoch 11: val_accuracy did not improve from 0.86084\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 2s/step - accuracy: 0.9146 - loss: 0.2503 - val_accuracy: 0.8569 - val_loss: 0.4304 - learning_rate: 0.0010\n",
      "Epoch 12/12\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590ms/step - accuracy: 0.9209 - loss: 0.2471\n",
      "Epoch 12: val_accuracy did not improve from 0.86084\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 675ms/step - accuracy: 0.9210 - loss: 0.2469 - val_accuracy: 0.8509 - val_loss: 0.4264 - learning_rate: 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Saved model: C:\\Users\\sagni\\Downloads\\Plastic Detector\\model.h5\n",
      "[INFO] Saved class indices: C:\\Users\\sagni\\Downloads\\Plastic Detector\\class_indices.pkl\n",
      "[INFO] Saved metrics: C:\\Users\\sagni\\Downloads\\Plastic Detector\\metrics.json\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 643ms/step\n",
      "[INFO] Saved validation predictions: C:\\Users\\sagni\\Downloads\\Plastic Detector\\val_predictions.json\n",
      "[INFO] Saved run config: C:\\Users\\sagni\\Downloads\\Plastic Detector\\run_config.yaml\n",
      "\n",
      "[DONE] All artifacts saved to: C:\\Users\\sagni\\Downloads\\Plastic Detector\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import yaml\n",
    "import pickle\n",
    "import random\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "# ----------------------------\n",
    "# CONFIG (Windows raw strings)\n",
    "# ----------------------------\n",
    "DATA_DIRS = [\n",
    "    r\"C:\\Users\\sagni\\Downloads\\Plastic Detector\\archive\\dataset-resized\\plastic\",\n",
    "    r\"C:\\Users\\sagni\\Downloads\\Plastic Detector\\archive\\dataset-resized\\trash\",\n",
    "    r\"C:\\Users\\sagni\\Downloads\\Plastic Detector\\archive\\dataset-resized\\paper\",\n",
    "    r\"C:\\Users\\sagni\\Downloads\\Plastic Detector\\archive\\dataset-resized\\metal\",\n",
    "    r\"C:\\Users\\sagni\\Downloads\\Plastic Detector\\archive\\dataset-resized\\glass\",\n",
    "    r\"C:\\Users\\sagni\\Downloads\\Plastic Detector\\archive\\dataset-resized\\cardboard\",\n",
    "]\n",
    "# Parent directory that contains all the class folders:\n",
    "DATA_ROOT = str(Path(DATA_DIRS[0]).parent)  # ...\\archive\\dataset-resized\n",
    "\n",
    "OUTPUT_DIR = r\"C:\\Users\\sagni\\Downloads\\Plastic Detector\"\n",
    "MODEL_H5 = str(Path(OUTPUT_DIR) / \"model.h5\")\n",
    "CLASS_PKL = str(Path(OUTPUT_DIR) / \"class_indices.pkl\")\n",
    "RUN_YAML  = str(Path(OUTPUT_DIR) / \"run_config.yaml\")\n",
    "METRICS_JSON = str(Path(OUTPUT_DIR) / \"metrics.json\")\n",
    "VAL_PRED_JSON = str(Path(OUTPUT_DIR) / \"val_predictions.json\")\n",
    "\n",
    "# Training hyperparams\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 12\n",
    "VAL_SPLIT = 0.2\n",
    "SEED = 42\n",
    "LEARNING_RATE = 1e-3\n",
    "AUGMENT = True  # Turn off if you want pure baseline\n",
    "\n",
    "# ----------------------------\n",
    "# Reproducibility\n",
    "# ----------------------------\n",
    "def set_seed(seed=SEED):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "set_seed(SEED)\n",
    "\n",
    "# ----------------------------\n",
    "# Prepare output directory\n",
    "# ----------------------------\n",
    "Path(OUTPUT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ----------------------------\n",
    "# Verify folders exist\n",
    "# ----------------------------\n",
    "expected_classes = sorted([Path(p).name for p in DATA_DIRS])\n",
    "if not Path(DATA_ROOT).exists():\n",
    "    raise FileNotFoundError(f\"DATA_ROOT not found: {DATA_ROOT}\")\n",
    "for p in DATA_DIRS:\n",
    "    if not Path(p).exists():\n",
    "        raise FileNotFoundError(f\"Class folder missing: {p}\")\n",
    "\n",
    "print(\"[INFO] Data root:\", DATA_ROOT)\n",
    "print(\"[INFO] Classes:\", expected_classes)\n",
    "\n",
    "# ----------------------------\n",
    "# Data generators\n",
    "# ----------------------------\n",
    "if AUGMENT:\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        preprocessing_function=preprocess_input,\n",
    "        validation_split=VAL_SPLIT,\n",
    "        rotation_range=15,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        zoom_range=0.1,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode=\"nearest\",\n",
    "    )\n",
    "else:\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        preprocessing_function=preprocess_input,\n",
    "        validation_split=VAL_SPLIT,\n",
    "    )\n",
    "\n",
    "val_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    validation_split=VAL_SPLIT\n",
    ")\n",
    "\n",
    "# flow_from_directory requires the structure:\n",
    "# DATA_ROOT/\n",
    "#   cardboard/\n",
    "#   glass/\n",
    "#   metal/\n",
    "#   paper/\n",
    "#   plastic/\n",
    "#   trash/\n",
    "# which matches your paths inside dataset-resized\n",
    "train_gen = train_datagen.flow_from_directory(\n",
    "    DATA_ROOT,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    classes=expected_classes,     # lock class order to your folders\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    subset=\"training\",\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "val_gen = val_datagen.flow_from_directory(\n",
    "    DATA_ROOT,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    classes=expected_classes,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=False,\n",
    "    subset=\"validation\",\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "num_classes = len(train_gen.class_indices)\n",
    "print(\"[INFO] Class indices:\", train_gen.class_indices)\n",
    "\n",
    "# ----------------------------\n",
    "# Build model (EfficientNetB0)\n",
    "# ----------------------------\n",
    "with tf.device(\"/GPU:0\" if tf.config.list_physical_devices(\"GPU\") else \"/CPU:0\"):\n",
    "    base = EfficientNetB0(include_top=False, input_shape=(*IMG_SIZE, 3), weights=\"imagenet\")\n",
    "    base.trainable = False  # freeze backbone first\n",
    "\n",
    "    inputs = layers.Input(shape=(*IMG_SIZE, 3))\n",
    "    x = base(inputs, training=False)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "    model = models.Model(inputs, outputs)\n",
    "\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "    model.compile(optimizer=opt, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    model.summary()\n",
    "\n",
    "# ----------------------------\n",
    "# Callbacks\n",
    "# ----------------------------\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor=\"val_accuracy\", patience=3, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=2, min_lr=1e-6, verbose=1),\n",
    "    ModelCheckpoint(MODEL_H5, monitor=\"val_accuracy\", save_best_only=True, verbose=1)\n",
    "]\n",
    "\n",
    "# ----------------------------\n",
    "# Train\n",
    "# ----------------------------\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Optionally unfreeze and fine-tune last blocks (quick fine-tune)\n",
    "# Uncomment to fine-tune:\n",
    "# base.trainable = True\n",
    "# for layer in base.layers[:-40]:\n",
    "#     layer.trainable = False\n",
    "# model.compile(optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "#               loss=\"categorical_crossentropy\",\n",
    "#               metrics=[\"accuracy\"])\n",
    "# history_ft = model.fit(train_gen, validation_data=val_gen, epochs=4, callbacks=callbacks, verbose=1)\n",
    "\n",
    "# Ensure best model saved (ModelCheckpoint already did); also save current graph as backup\n",
    "model.save(MODEL_H5)\n",
    "print(f\"[INFO] Saved model: {MODEL_H5}\")\n",
    "\n",
    "# ----------------------------\n",
    "# Save class indices (PKL)\n",
    "# ----------------------------\n",
    "with open(CLASS_PKL, \"wb\") as f:\n",
    "    pickle.dump(train_gen.class_indices, f)\n",
    "print(f\"[INFO] Saved class indices: {CLASS_PKL}\")\n",
    "\n",
    "# ----------------------------\n",
    "# Compute and save metrics JSON\n",
    "# ----------------------------\n",
    "final_train_acc = float(history.history[\"accuracy\"][-1])\n",
    "final_train_loss = float(history.history[\"loss\"][-1])\n",
    "final_val_acc = float(history.history[\"val_accuracy\"][-1])\n",
    "final_val_loss = float(history.history[\"val_loss\"][-1])\n",
    "\n",
    "metrics_payload = {\n",
    "    \"timestamp\": datetime.datetime.now().isoformat(),\n",
    "    \"epochs_run\": len(history.history[\"loss\"]),\n",
    "    \"final\": {\n",
    "        \"train_accuracy\": final_train_acc,\n",
    "        \"train_loss\": final_train_loss,\n",
    "        \"val_accuracy\": final_val_acc,\n",
    "        \"val_loss\": final_val_loss\n",
    "    },\n",
    "    \"history\": {k: [float(x) for x in v] for k, v in history.history.items()}\n",
    "}\n",
    "\n",
    "with open(METRICS_JSON, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(metrics_payload, f, indent=2)\n",
    "print(f\"[INFO] Saved metrics: {METRICS_JSON}\")\n",
    "\n",
    "# ----------------------------\n",
    "# Make & save validation predictions (filenames + top1)\n",
    "# ----------------------------\n",
    "# Note: val_gen.filenames holds relative paths; classes mapping in class_indices\n",
    "idx_to_class = {v: k for k, v in train_gen.class_indices.items()}\n",
    "\n",
    "val_gen.reset()\n",
    "all_probs = model.predict(val_gen, verbose=1)\n",
    "top1_idx = np.argmax(all_probs, axis=1)\n",
    "top1_conf = np.max(all_probs, axis=1)\n",
    "\n",
    "val_records = []\n",
    "for rel_path, pred_i, conf in zip(val_gen.filenames, top1_idx, top1_conf):\n",
    "    val_records.append({\n",
    "        \"file\": rel_path.replace(\"\\\\\", \"/\"),\n",
    "        \"pred_class\": idx_to_class[int(pred_i)],\n",
    "        \"confidence\": float(conf)\n",
    "    })\n",
    "\n",
    "with open(VAL_PRED_JSON, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(val_records, f, indent=2)\n",
    "print(f\"[INFO] Saved validation predictions: {VAL_PRED_JSON}\")\n",
    "\n",
    "# ----------------------------\n",
    "# Save YAML run config\n",
    "# ----------------------------\n",
    "run_cfg = {\n",
    "    \"run\": {\n",
    "        \"timestamp\": datetime.datetime.now().isoformat(),\n",
    "        \"seed\": SEED\n",
    "    },\n",
    "    \"data\": {\n",
    "        \"data_root\": DATA_ROOT,\n",
    "        \"class_dirs\": DATA_DIRS,\n",
    "        \"classes\": expected_classes,\n",
    "        \"val_split\": VAL_SPLIT,\n",
    "        \"image_size\": list(IMG_SIZE),\n",
    "        \"batch_size\": BATCH_SIZE,\n",
    "        \"augment\": AUGMENT\n",
    "    },\n",
    "    \"model\": {\n",
    "        \"architecture\": \"EfficientNetB0\",\n",
    "        \"transfer_learning\": True,\n",
    "        \"frozen_base\": True,\n",
    "        \"optimizer\": \"Adam\",\n",
    "        \"learning_rate\": LEARNING_RATE,\n",
    "        \"epochs\": EPOCHS,\n",
    "        \"num_classes\": num_classes\n",
    "    },\n",
    "    \"artifacts\": {\n",
    "        \"model_h5\": MODEL_H5,\n",
    "        \"class_indices_pkl\": CLASS_PKL,\n",
    "        \"metrics_json\": METRICS_JSON,\n",
    "        \"val_predictions_json\": VAL_PRED_JSON\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(RUN_YAML, \"w\", encoding=\"utf-8\") as f:\n",
    "    yaml.safe_dump(run_cfg, f, sort_keys=False, allow_unicode=True)\n",
    "print(f\"[INFO] Saved run config: {RUN_YAML}\")\n",
    "\n",
    "print(\"\\n[DONE] All artifacts saved to:\", OUTPUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d71bdf-5923-4372-8434-84e5a7707541",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (moviepy)",
   "language": "python",
   "name": "py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
