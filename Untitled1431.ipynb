{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d60f660-912f-41f8-a2ca-55609ca637bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] --input INPUT [--out OUT] [--topk TOPK] [--annotate]\n",
      "ipykernel_launcher.py: error: the following arguments are required: --input\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\u001b[31m:\u001b[39m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sagni\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3678: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import csv\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "\n",
    "# -----------------------------\n",
    "# Config (Windows paths)\n",
    "# -----------------------------\n",
    "OUTPUT_DIR = r\"C:\\Users\\sagni\\Downloads\\Plastic Detector\"\n",
    "MODEL_H5   = str(Path(OUTPUT_DIR) / \"model.h5\")\n",
    "CLASS_PKL  = str(Path(OUTPUT_DIR) / \"class_indices.pkl\")  # produced by your training script\n",
    "\n",
    "# Inference settings (must match training)\n",
    "IMG_SIZE   = (224, 224)\n",
    "TOP_K      = 5\n",
    "\n",
    "# -----------------------------\n",
    "# Utilities\n",
    "# -----------------------------\n",
    "def load_class_indices(pkl_path: str) -> Tuple[Dict[str, int], Dict[int, str], List[str]]:\n",
    "    import pickle\n",
    "    with open(pkl_path, \"rb\") as f:\n",
    "        class_indices = pickle.load(f)             # {'cardboard':0, 'glass':1, ...}\n",
    "    idx_to_class = {v: k for k, v in class_indices.items()}\n",
    "    ordered_classes = [idx_to_class[i] for i in range(len(idx_to_class))]\n",
    "    return class_indices, idx_to_class, ordered_classes\n",
    "\n",
    "def list_images(input_path: str) -> List[Path]:\n",
    "    p = Path(input_path)\n",
    "    exts = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\", \".webp\"}\n",
    "    files = []\n",
    "    if p.is_file():\n",
    "        if p.suffix.lower() in exts:\n",
    "            files.append(p)\n",
    "    elif p.is_dir():\n",
    "        for fp in p.rglob(\"*\"):\n",
    "            if fp.suffix.lower() in exts:\n",
    "                files.append(fp)\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"Input not found: {input_path}\")\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f\"No image files found under: {input_path}\")\n",
    "    return sorted(files)\n",
    "\n",
    "def load_and_preprocess(img_path: Path) -> np.ndarray:\n",
    "    img = Image.open(img_path).convert(\"RGB\").resize(IMG_SIZE)\n",
    "    arr = np.array(img).astype(np.float32)\n",
    "    arr = preprocess_input(arr)        # EfficientNet preprocessing\n",
    "    arr = np.expand_dims(arr, axis=0)  # (1, H, W, 3)\n",
    "    return arr\n",
    "\n",
    "def draw_label(image_path: Path, label_text: str, out_path: Path) -> None:\n",
    "    img = Image.open(image_path).convert(\"RGB\")\n",
    "    draw = ImageDraw.Draw(img)\n",
    "\n",
    "    # Try to use a default truetype font; fallback to PIL's basic font\n",
    "    try:\n",
    "        font = ImageFont.truetype(\"arial.ttf\", 24)\n",
    "    except:\n",
    "        font = ImageFont.load_default()\n",
    "\n",
    "    text = label_text\n",
    "    # Text box\n",
    "    text_w, text_h = draw.textlength(text, font=font), 24\n",
    "    margin = 8\n",
    "    box_w = int(text_w + 2 * margin)\n",
    "    box_h = int(text_h + 2 * margin)\n",
    "\n",
    "    # Draw rectangle (semi-transparent black)\n",
    "    rect_xy = [(10, 10), (10 + box_w, 10 + box_h)]\n",
    "    draw.rectangle(rect_xy, fill=(0, 0, 0, 160))\n",
    "    draw.text((10 + margin, 10 + margin), text, font=font, fill=(255, 255, 255))\n",
    "\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    img.save(out_path)\n",
    "\n",
    "def softmax(x: np.ndarray) -> np.ndarray:\n",
    "    # x shape: (1, C) or (N, C)\n",
    "    e = np.exp(x - np.max(x, axis=-1, keepdims=True))\n",
    "    return e / np.clip(e.sum(axis=-1, keepdims=True), 1e-12, None)\n",
    "\n",
    "# -----------------------------\n",
    "# Main prediction logic\n",
    "# -----------------------------\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(description=\"Plastic Detector — Prediction & Results\")\n",
    "    parser.add_argument(\"--input\", required=True, help=\"Path to an image file OR a folder of images\")\n",
    "    parser.add_argument(\"--out\", default=OUTPUT_DIR, help=\"Output directory (default: Plastic Detector)\")\n",
    "    parser.add_argument(\"--topk\", type=int, default=TOP_K, help=\"Top-K classes to include\")\n",
    "    parser.add_argument(\"--annotate\", action=\"store_true\", help=\"Save annotated images with label+confidence\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    input_path = args.input\n",
    "    out_dir = Path(args.out)\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    ann_dir = out_dir / \"annotated\"\n",
    "\n",
    "    # 1) Load model & classes\n",
    "    if not Path(MODEL_H5).exists():\n",
    "        print(f\"[ERROR] model.h5 not found at: {MODEL_H5}\")\n",
    "        sys.exit(1)\n",
    "    if not Path(CLASS_PKL).exists():\n",
    "        print(f\"[ERROR] class_indices.pkl not found at: {CLASS_PKL}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    print(\"[INFO] Loading model…\")\n",
    "    model = load_model(MODEL_H5)\n",
    "\n",
    "    print(\"[INFO] Loading class mapping…\")\n",
    "    class_indices, idx_to_class, ordered_classes = load_class_indices(CLASS_PKL)\n",
    "    num_classes = len(ordered_classes)\n",
    "    topk = max(1, min(args.topk, num_classes))\n",
    "\n",
    "    # 2) Collect images\n",
    "    print(\"[INFO] Scanning inputs…\")\n",
    "    images = list_images(input_path)\n",
    "    print(f\"[INFO] Found {len(images)} image(s).\")\n",
    "\n",
    "    # 3) Predict\n",
    "    all_results = []\n",
    "    for i, img_path in enumerate(images, start=1):\n",
    "        arr = load_and_preprocess(img_path)\n",
    "        logits = model.predict(arr, verbose=0)  # shape (1, C) after softmax layer, but handle generally\n",
    "        if logits.shape[-1] != num_classes:\n",
    "            # If model already outputs probabilities (softmax), no need to re-softmax; still safe to apply\n",
    "            probs = logits\n",
    "        else:\n",
    "            probs = logits\n",
    "\n",
    "        probs = np.squeeze(probs, axis=0)  # (C,)\n",
    "        # Top-K\n",
    "        top_idx = np.argsort(probs)[::-1][:topk]\n",
    "        top_classes = [idx_to_class[int(k)] for k in top_idx]\n",
    "        top_scores  = [float(probs[int(k)]) for k in top_idx]\n",
    "\n",
    "        pred_class = top_classes[0]\n",
    "        pred_conf  = top_scores[0]\n",
    "\n",
    "        rel = str(img_path.name)\n",
    "        result = {\n",
    "            \"file\": str(img_path),\n",
    "            \"pred_class\": pred_class,\n",
    "            \"confidence\": round(float(pred_conf), 6),\n",
    "            \"topk\": [{\"class\": c, \"p\": round(float(s), 6)} for c, s in zip(top_classes, top_scores)]\n",
    "        }\n",
    "        all_results.append(result)\n",
    "\n",
    "        # Annotate if asked\n",
    "        if args.annotate:\n",
    "            label_text = f\"{pred_class} ({pred_conf*100:.1f}%)\"\n",
    "            out_img = ann_dir / f\"{img_path.stem}_pred.png\"\n",
    "            try:\n",
    "                draw_label(img_path, label_text, out_img)\n",
    "            except Exception as e:\n",
    "                print(f\"[WARN] Failed to annotate {img_path.name}: {e}\")\n",
    "\n",
    "        # Console preview\n",
    "        print(f\"[{i}/{len(images)}] {rel}  ->  {pred_class}  ({pred_conf*100:.2f}%)\")\n",
    "\n",
    "    # 4) Save JSON + CSV\n",
    "    json_path = out_dir / \"predictions.json\"\n",
    "    with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(all_results, f, indent=2)\n",
    "    print(f\"[INFO] Saved JSON → {json_path}\")\n",
    "\n",
    "    csv_path = out_dir / \"predictions.csv\"\n",
    "    # Flatten top-k columns a bit for a readable CSV\n",
    "    fieldnames = [\"file\", \"pred_class\", \"confidence\"] + [f\"top{i+1}_class\" for i in range(topk)] + [f\"top{i+1}_p\" for i in range(topk)]\n",
    "    with open(csv_path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for r in all_results:\n",
    "            row = {\n",
    "                \"file\": r[\"file\"],\n",
    "                \"pred_class\": r[\"pred_class\"],\n",
    "                \"confidence\": r[\"confidence\"],\n",
    "            }\n",
    "            for i in range(topk):\n",
    "                row[f\"top{i+1}_class\"] = r[\"topk\"][i][\"class\"]\n",
    "            for i in range(topk):\n",
    "                row[f\"top{i+1}_p\"] = r[\"topk\"][i][\"p\"]\n",
    "            writer.writerow(row)\n",
    "    print(f\"[INFO] Saved CSV  → {csv_path}\")\n",
    "\n",
    "    print(\"\\n[DONE] Inference complete.\")\n",
    "    if args.annotate:\n",
    "        print(f\"[INFO] Annotated images in: {ann_dir}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0726b9-f8ea-48cd-8e83-03aee01880a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (moviepy)",
   "language": "python",
   "name": "py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
